{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ad0fed",
   "metadata": {},
   "source": [
    "# Fichier Google Colab pour faire tourner le projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des fichiers de Google Drive avec le jeu de données et le code\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38334888",
   "metadata": {},
   "source": [
    "# 0. Importation des fichiers et Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalation de Tensorflow_io\n",
    "# Risque de problème de version\n",
    "\n",
    "!pip install tensorflow_io\n",
    "\n",
    "# si ça ne marche pas il faut exécuté les commandes suivantes :\n",
    "#!pip uninstall tensorflow-io\n",
    "#!pip install tensorflow-io==0.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436175a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des fichiers zip\n",
    "# Extraction des fichiers codes\n",
    "from zipfile import ZipFile\n",
    "\n",
    "file = \"drive/MyDrive/datascientest_project.zip\"\n",
    "with ZipFile(file, 'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a41a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des fichiers Model si déjà existant\n",
    "file = \"drive/MyDrive/Model.zip\"\n",
    "with ZipFile(file, 'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c61cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des fichiers history pour récupérer l'historique si déjà existant\n",
    "file = \"drive/MyDrive/history.zip\"\n",
    "with ZipFile(file, 'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffe8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques utilisées\n",
    "\n",
    "################   base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "################   gestion du temps et des fichiers\n",
    "from time import time     # Importer la bibliothèque time et calcul du temps au début de l'exécution (t0)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os         # Pour lire les fichier\n",
    "\n",
    "\n",
    "################   gestion audio\n",
    "import librosa                # pour analyse des audio\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "################   Affichage et image\n",
    "import IPython.display as ipd  # pour lecture audio\n",
    "\n",
    "import matplotlib.pyplot as plt        # Pour les graphique et figures\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "###############  tensorflow pour modèle et formatage entrée\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf73e82",
   "metadata": {},
   "source": [
    "# 1. Importation module perso du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Module_reco_voc as prepro\n",
    "import Module_reco_voc_2 as mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cccc6d",
   "metadata": {},
   "source": [
    "# 2. Partie preprocess transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28149e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "df = prepro.Recuperation_data_txt()\n",
    "\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bb0e1",
   "metadata": {},
   "source": [
    "# 3. Partie preprocess audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9746c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de la durée de l'audio et stockage dans le dataframe\n",
    "t0 = time()\n",
    "\n",
    "prepro.Preprocess_simple()\n",
    "\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f013e",
   "metadata": {},
   "source": [
    "# 4. Partie Split des data en jeux d'entraînement, de validation et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation du dataframe en jeu de test, de validation et d'entraînement\n",
    "t0 = time()\n",
    "\n",
    "prepro.split_dataframe()\n",
    "\n",
    "t1 = time() - t0\n",
    "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d8fbe",
   "metadata": {},
   "source": [
    "# 5. Préparation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du dataframe splité\n",
    "df_train, df_val, df_test = prepro.Lecture_data_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b14291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction de maping du texte en nombre\n",
    "\n",
    "# Liste des caractères acceptés\n",
    "caracteres = [x for x in \"abcdefghijklmnopqrstuvwxyz' \"]\n",
    "\n",
    "# Mapping des caractères en chiffres (int)\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=caracteres, oov_token=\"\")\n",
    "\n",
    "# Mapping (retour) des chiffres à des caractères\n",
    "num_to_char = keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction servant au préprocess final des données pour passer d'un dataframe à un dataset de tensorflow\n",
    "#\n",
    "# Il y a deux parties :\n",
    "#                       - La première : transformation de l'audio en spectrogramme\n",
    "#                       - La seconde : Mapping de la transcription en nombre\n",
    "\n",
    "#================== 1. Transformation de l'audio en spectrogramme ==================#\n",
    "# Paramètre de la transformé courte de fournier utilisé pour l'optention du spectrogramme\n",
    "# Taille de la fenêtre en échantillons audio\n",
    "frame_length = 512\n",
    "\n",
    "# Pas d'échantillonnage entre le départ de deux fenêtre\n",
    "frame_step = 128\n",
    "\n",
    "# Nombre d'échantillon pour une durée fixé sur laquelle on applique la FFT\n",
    "fft_length = 512\n",
    "\n",
    "# Pour optimiser le temps de calcul il est recommandé d'utiliser un n_fft = 2^n (puissance de 2)\n",
    "# (2/4/8/16/32/64/128/256/512/1024/2048/4096/...)\n",
    "# Dans notre cas (pour le traitement de la voix) il est recommander d'utiliser 512 \n",
    "# cela correspond à une période d'échantillonnage de 32 milisecondes\n",
    "\n",
    "\n",
    "#================== 2. Mapping de la transcription en nombre ==================#\n",
    "def Recup_spectrogramme_transcription(fichier_audio, transcription):\n",
    "    #  ==== Récupération du spectrogramme ==== #\n",
    "    # Lecture du fichier audio\n",
    "    fichier = tf.io.read_file(fichier_audio)\n",
    "\n",
    "    # Decodage du fichier audio .flac\n",
    "    audio = tfio.audio.decode_flac(fichier, dtype = tf.int16)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "    # Passage de l'audio en float32\n",
    "    audio = tf.cast(audio, tf.float32)    # pas utile dans notre cas\n",
    "\n",
    "    # Récupération spectrogramme\n",
    "    spectrogram = tf.signal.stft(audio,\n",
    "                                 frame_length = frame_length,\n",
    "                                 frame_step = frame_step,\n",
    "                                 fft_length = fft_length\n",
    "                                )\n",
    "\n",
    "    # On ne conserve que la racine carré de la valeur absolue du nombre du complexe\n",
    "    spectrogram = tf.abs(spectrogram)              # valeur absolue\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)    # racine carrée\n",
    "\n",
    "    # normalisation du spectrogramme\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "\n",
    "\n",
    "    # ==== Mapping de la transcription ==== #\n",
    "    # Passage de la transcription en minuscules\n",
    "    transcription = tf.strings.lower(transcription)\n",
    "\n",
    "    # Séparationt de la transcription\n",
    "    transcription = tf.strings.unicode_split(transcription, input_encoding=\"UTF-8\")\n",
    "\n",
    "    # Map les caractères de la transcription en nombres\n",
    "    transcription = char_to_num(transcription)\n",
    "\n",
    "    return spectrogram, transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Génération des dataset à partir des dataframes ==== #\n",
    "\n",
    "# taille des batch\n",
    "batch_size = 28\n",
    "\n",
    "# Création du dataset d'entrainnement\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_train[\"chemin\"]), list(df_train[\"transcription\"]))\n",
    ")\n",
    "train_dataset = (\n",
    "    train_dataset.map(Recup_spectrogramme_transcription, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    #.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Création du dataset de validation\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"chemin\"]), list(df_val[\"transcription\"]))\n",
    ")\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(Recup_spectrogramme_transcription, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ef5f25",
   "metadata": {},
   "source": [
    "# 6. Partie construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603fefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dossier (si inexistant) pour les sauvegarde du modèle au cours de l'entraînement\n",
    "checkpoint_doss = \"./save_model_run\"\n",
    "\n",
    "if not os.path.exists(checkpoint_doss):\n",
    "    os.makedirs(checkpoint_doss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899be2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Restoration du modèle ou création d'un nouveau modèle === #\n",
    "model = mod.Fabriquer_ou_restorer_model(output_dim = char_to_num.vocabulary_size(), checkpoint_doss = checkpoint_doss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du callbacks ModelCheckpoint pour sauvegarder le modèle tous les x batch\n",
    "ModelCheckpoint = keras.callbacks.ModelCheckpoint(filepath=checkpoint_doss + \"/Model.hdf5\",\n",
    "                                                  verbose=1,\n",
    "                                                  save_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f780663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du callback EarlyStopping pour stopper l'entraînement du modèle\n",
    "# si la perte sur le dataset de validation n'a pas évolué pendant 3 épochs à partir de la 25eme épochs\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, start_from_epoch = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b18511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du callback ReduceLROnPlateau pour réduire le learning rate\n",
    "# si la perte sur le dataset de validation n'a pas évolué pendant 3 épochs avec une valeur seuil de 1e-7\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=3, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fedeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la liste des callbacks utilisés\n",
    "callbacks = [ModelCheckpoint,\n",
    "             early_stopping,\n",
    "             reduce_lr\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2754b",
   "metadata": {},
   "source": [
    "# 7. Partie Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainnementr du modèle\n",
    "History = model.fit(train_dataset,\n",
    "                    epochs = 20,\n",
    "                    callbacks = callbacks,\n",
    "                    validation_data = validation_dataset)\n",
    "\n",
    "files.download(\"./save_model_run/Model.hdf5\")\n",
    "\n",
    "mod.sauvegarde_history_file(History)\n",
    "\n",
    "files.download(\"history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89889f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de la bibliothèque pour télécharger les résultats\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement du modèle post-entrainement \n",
    "files.download(\"./save_model_run/Model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729eb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de l'historique de l'entraînement\n",
    "mod.sauvegarde_history_file(History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aeeefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement de l'historique du modèle post-entrainement \n",
    "files.download(\"history.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa5262",
   "metadata": {},
   "source": [
    "# 8. Partie Analyse du modèle et Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a23214",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.analyze_metrics(History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71716e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('history.csv')\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,4))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(history['epochs'], history['loss'], label='Loss')\n",
    "ax1.plot(history['epochs'], history['val_loss'], label='Validation Loss')\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Valeur loss')\n",
    "ax1.legend()\n",
    "plt.title('Valeur loss par epoch lors de l\\'entraînement')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(history['epochs'], history['CER_metric'], label='CER_metric')\n",
    "ax2.plot(history['epochs'], history['val_CER_metric'], label='Validation CER_metric')\n",
    "\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Valeur metric')\n",
    "ax2.legend()\n",
    "\n",
    "plt.title('Métriques par epoch lors de l\\'entraînement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dataset de test final à partir de df_test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_test[\"chemin\"]), list(df_test[\"transcription\"]))\n",
    ")\n",
    "test_dataset = (\n",
    "    test_dataset.map(Recup_spectrogramme_transcription, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour décoder la prédiction en texte\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaisson cible / prédiction sur le jeu de donnée test\n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in test_dataset.take(1):\n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "    for label in y:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        targets.append(label)\n",
    "\n",
    "for i in np.random.randint(0, len(predictions), 5):\n",
    "    print(f\"Target    : {targets[i]}\")\n",
    "    print(f\"Prediction: {predictions[i]}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916944e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaisson cible / prédiction sur le jeu de donnée train\n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in train_dataset.take(1):\n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "    for label in y:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        targets.append(label)\n",
    "\n",
    "for i in np.random.randint(0, len(predictions), 5):\n",
    "    print(f\"Target    : {targets[i]}\")\n",
    "    print(f\"Prediction: {predictions[i]}\")\n",
    "    print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
